{"cells":[{"cell_type":"markdown","metadata":{"id":"9uxQLCBR8-F8"},"source":["# 라이브러리 불러오기"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14024,"status":"ok","timestamp":1728001427869,"user":{"displayName":"Ian You","userId":"13262938928318481713"},"user_tz":-540},"id":"RmkYtdOO8-F_","outputId":"941c98de-2a64-486f-aae7-e6af825db0aa"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","from sklearn.model_selection import KFold\n","\n","import lightgbm as lgb\n","from catboost import CatBoostRegressor, Pool\n","import wandb\n","from wandb.integration.lightgbm import log_summary\n","from wandb.integration.catboost import WandbCallback\n","import optuna\n","optuna.logging.set_verbosity(optuna.logging.INFO)  # optuna log 설정\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import func.preprocessing as pp\n","import func.features as ft\n","import func.models as mdl\n","from func.utils import lgb_wandb_callback"]},{"cell_type":"markdown","metadata":{},"source":["# WandB 설정"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masduianm\u001b[0m (\u001b[33mrecsys008-naver-boostcamp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["recsys008-naver-boostcamp\n"]}],"source":["wandb.login()\n","print(wandb.api.default_entity)"]},{"cell_type":"markdown","metadata":{"id":"mqCLjTRj8-GA"},"source":["# 랜덤 시드 설정"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1728001427869,"user":{"displayName":"Ian You","userId":"13262938928318481713"},"user_tz":-540},"id":"qbSLEr518-GB"},"outputs":[],"source":["RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"FdLe3hAC8-GB"},"source":["# 데이터 불러오기"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":14342,"status":"ok","timestamp":1728001467235,"user":{"displayName":"Ian You","userId":"13262938928318481713"},"user_tz":-540},"id":"1XA9P3kh8-GB"},"outputs":[],"source":["path = \"../../data/\"  # 알잘딱 수정\n","file_dict = {'train':'train_data', 'test':'test_data', \n","             'sample_submission':'sample_submission', 'parkInfo':'park', \n","             'schoolinfo':'school', 'subwayInfo':'subway'}\n","\n","for f, d in file_dict.items():\n","    exec(f\"{d} = pp.load_data(path + '{f}.csv')\")\n"]},{"cell_type":"markdown","metadata":{"id":"bCMiKws_0YcN"},"source":["# 중복 값 처리"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["train_data = pp.preprocess_data(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["# 가장 가까운 지하철 거리 추가"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# 각 아파트에 대해 가까운 지하철역 거리 추가\n","train_data = ft.calculate_nearest_subway_distance(train_data, subway)\n","test_data = ft.calculate_nearest_subway_distance(test_data, subway)"]},{"cell_type":"markdown","metadata":{},"source":["# 학교 레벨별로 가장 가까운 학교 추가"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# 각 아파트에 대해 가까운 학교 거리 추가\n","train_data = ft.calculate_nearest_school_distance(train_data, school)\n","test_data = ft.calculate_nearest_school_distance(test_data, school)\n"]},{"cell_type":"markdown","metadata":{},"source":["# 특정 반경(radius) 내 공원 밀도"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 18491/18491 [00:13<00:00, 1330.00it/s]\n","100%|██████████| 11885/11885 [00:05<00:00, 2118.37it/s]\n"]}],"source":["radius_km = 3\n","item_name = 'park'\n","\n","# 유니크한 아파트 좌표로 공원 개수와 밀도 계산 후 결과를 원래 데이터에 매핑\n","train_data = ft.map_item_density_with_area(train_data, park, radius_km, item_name)\n","test_data = ft.map_item_density_with_area(test_data, park, radius_km, item_name)"]},{"cell_type":"markdown","metadata":{},"source":["# 특정 거리(distance) 내 레벨별 학교 개수"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 18491/18491 [00:12<00:00, 1470.22it/s]\n","100%|██████████| 11885/11885 [00:07<00:00, 1502.89it/s]\n"]}],"source":["# 각 레벨에 대해 다른 거리 범위를 설정\n","distance_kms = {\n","    'elementary': 1,  # 1km 이내\n","    'middle': 5,      # 3km 이내\n","    'high': 5         # 5km 이내\n","}\n","\n","train_data = ft.map_school_level_counts(train_data, school, distance_kms, n_jobs=8)\n","test_data = ft.map_school_level_counts(test_data, school, distance_kms, n_jobs=8)"]},{"cell_type":"markdown","metadata":{"id":"o81426wF8-GD"},"source":["# Holdout 데이터셋 설정 (예: 2023년 7월부터 12월까지의 데이터)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1728003489762,"user":{"displayName":"Ian You","userId":"13262938928318481713"},"user_tz":-540},"id":"tKD6UEcb8-GD"},"outputs":[],"source":["# 전체 재학습 데이터\n","all_data = train_data.copy()\n","X_all, y_all = pp.split_X_y(all_data, 'deposit')\n","X_test = test_data.copy()\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1728003491324,"user":{"displayName":"Ian You","userId":"13262938928318481713"},"user_tz":-540},"id":"J1QQyNic8-GE"},"outputs":[],"source":["holdout_start, holdout_end = 202307, 202312\n","train_data, holdout_data = pp.split_holdout_data(train_data.copy(), holdout_start, holdout_end)\n","X_train, y_train = pp.split_X_y(train_data, 'deposit')\n","X_holdout, y_holdout = pp.split_X_y(holdout_data, 'deposit')\n"]},{"cell_type":"markdown","metadata":{},"source":["# DBSCAN 클러스터링 \n","* 경도, 위도 스케일링 후 DBSCAN으로 train 기반하여 클러스터 생성\n","* holdout(=validation)은 경도,위도 기준 가장 가까운 train 샘플의 라벨을 할당"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# # Train 데이터에 DBSCAN 적용\n","# # 클러스터 정보를 포함한 데이터셋 생성\n","# X_train['cluster'], X_holdout['cluster'] = ft.apply_dbscan_clustering(X_train, X_holdout)"]},{"cell_type":"markdown","metadata":{},"source":["# 모델 훈련"]},{"cell_type":"markdown","metadata":{},"source":["## 피처 선택"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# 피처 선택\n","train_columns = ['area_m2', 'contract_year_month', 'floor', 'built_year', 'latitude', 'longitude',\n","                 'nearest_subway_distance',  'nearest_elementary_distance', 'nearest_middle_distance',\n","                 'nearest_high_distance', 'park_density', 'elementary', 'middle', 'high']\n","\n","X_train = X_train[train_columns]\n","X_holdout = X_holdout[train_columns]\n","X_all = X_all[train_columns]\n","X_test = X_test[train_columns]"]},{"cell_type":"markdown","metadata":{"id":"BC_OAK1A8-GF"},"source":["# LightGBM 모델 훈련"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lgb_params = {\n","    'objective': 'regression',\n","    'metric': ['mae', 'rmse'],\n","    'boosting_type': 'gbdt',\n","    'num_leaves': 1200,\n","    'min_samples': 20,\n","    'learning_rate': 0.035,\n","    'n_estimators': 2000,\n","    'feature_fraction': 0.65,\n","    'lambda_l1': 1.19,\n","    'lambda_l2': 4.38,\n","    'verbose': -1,\n","    'random_state': 42\n","}\n","\n","lgb_model = mdl.train_lgb(X_train, y_train, X_holdout, y_holdout, lgb_params, \n","                                 project_name=\"Trash can\", \n","                                 experiment_name=\"v6 + seasonal month\", \n","                                 entity_name=\"recsys008-naver-boostcamp\")"]},{"cell_type":"markdown","metadata":{},"source":["## 교차검증 학습"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 사용 예시\n","lgb_params = {\n","    'objective': 'regression',\n","    'metric': ['mae', 'rmse'],\n","    'boosting_type': 'gbdt',\n","    'num_leaves': 1200,\n","    'min_samples': 20,\n","    'learning_rate': 0.035,\n","    'n_estimators': 2000,\n","    'feature_fraction': 0.65,\n","    'lambda_l1': 1.19,\n","    'lambda_l2': 4.38,\n","    'verbose': -1,\n","    'random_state': 42\n","}\n","\n","# 모델 훈련 및 결과\n","models, oof_predictions = mdl.cross_validation_lgb_with_wandb(X_all, y_all, lgb_params, \n","                                                          project_name=\"lgbm CV\", \n","                                                          entity_name=\"recsys008-naver-boostcamp\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 테스트 데이터가 있다면 아래 코드를 사용\n","test_predictions = mdl.soft_voting_predict(models, X_test)\n","sample_submission['deposit'] = test_predictions\n","sample_submission.to_csv('output.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"markdown","metadata":{},"source":["## Optuna 파라미터 서칭"]},{"cell_type":"markdown","metadata":{},"source":["### 단일 학습/검증"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","\n","    # 하이퍼 파라미터 범위 지정\n","    params = {\n","        'metric': ['mae', 'rmse'],\n","        'num_leaves': trial.suggest_int('num_leaves', 1100, 1500, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.04, step=0.005),\n","        # 'n_estimators': trial.suggest_int('n_estimators', 1500, 2000, step=100),\n","        'n_estimators': 2000,\n","        'min_child_samples': trial.suggest_int('min_child_samples', 5, 30, step=5),\n","        # 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.8, step=0.05),  # 각 트리가 사용할 데이터의 비율 eg. 0.8이면 80퍼센트의 데이터 샘플만 사용\n","        # 'bagging_freq': trial.suggest_int('bagging_freq', 0, 5),  # 몇번째 트리마다 배깅을 적용할건지 eg. 5이면 5번째 트리마다 배깅 적용\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0, step=0.05),  # 각 트리가 사용할 컬럼의 비율 eg. 0.8이면 10개의 컬럼 중 8개만 사용\n","        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","        'num_threads': 4,\n","        'random_state': RANDOM_SEED,\n","        'verbose': 0,\n","    }\n","\n","    # lgb model 선언 및 훈련\n","    # LightGBM 데이터셋 생성\n","    train_data = lgb.Dataset(X_train, label=y_train)\n","    valid_data = lgb.Dataset(X_holdout, label=y_holdout, reference=train_data)\n","\n","    # LightGBM 모델 학습\n","    lgb_model = lgb.train(\n","        params,\n","        train_data,\n","        valid_sets=[valid_data],\n","        valid_names='validation',\n","        callbacks=[lgb.early_stopping(stopping_rounds=100)]\n","    )\n","\n","    # holdout에 대한 예측\n","    holdout_pred = lgb_model.predict(X_holdout)\n","    mae = mean_absolute_error(y_holdout, holdout_pred)\n","    # rmse = np.sqrt(mean_squared_error(y_holdout, holdout_pred))\n","    # r2 = r2_score(y_holdout, holdout_pred)\n","\n","    return mae\n","\n","\n","# Optuna 객체 생성\n","study = optuna.create_study(direction='minimize')\n","\n","# MAE 최적화 수행\n","study.optimize(objective,\n","               n_trials=100,  # 몇번의 서칭을 할건지\n","               n_jobs=2,  # 사용할 쓰레드의 수, -1이면 최대 실제 코어 개수\n",")\n","\n","# 최적 런과 파라미터 출력\n","best_params = study.best_params\n","print(\"Best parameters:\", best_params)\n","print(\"Best MAE:\", study.best_value)"]},{"cell_type":"markdown","metadata":{},"source":["### kfold CV"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-10-21 16:12:52,312] A new study created in memory with name: no-name-b1302280-56b9-4759-b9a9-afecfc972b74\n"]},{"name":"stdout","output_type":"stream","text":["Training until validation scores don't improve for 100 rounds\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[1211]\tvalidation's l1: 4343.8\tvalidation's rmse: 7384.13\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 4 to 8), it may cause unexpected errors.\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 8 to 4), it may cause unexpected errors.\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[1806]\tvalidation's l1: 4330.82\tvalidation's rmse: 7387.05\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 4 to 8), it may cause unexpected errors.\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 8 to 4), it may cause unexpected errors.\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[1604]\tvalidation's l1: 4314.88\tvalidation's rmse: 7332.04\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 4 to 8), it may cause unexpected errors.\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 8 to 4), it may cause unexpected errors.\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[1867]\tvalidation's l1: 4317.05\tvalidation's rmse: 7344.47\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 4 to 8), it may cause unexpected errors.\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 8 to 4), it may cause unexpected errors.\n","Training until validation scores don't improve for 100 rounds\n","Early stopping, best iteration is:\n","[1289]\tvalidation's l1: 4323.11\tvalidation's rmse: 7333.82\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 4 to 8), it may cause unexpected errors.\n","[LightGBM] [Warning] Detected that num_threads changed during training (from 8 to 4), it may cause unexpected errors.\n","Training until validation scores don't improve for 100 rounds\n"]}],"source":["def objective(trial):\n","    # 하이퍼파라미터 범위 지정\n","    params = {\n","        'objective': 'regression',\n","        'metric': ['mae', 'rmse'],\n","        'boosting_type': 'gbdt',\n","        'num_leaves': trial.suggest_int('num_leaves', 1100, 1500, step=100),\n","        'min_child_samples': trial.suggest_int('min_child_samples', 10, 30, step=5),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.05, step=0.005),\n","        'n_estimators': 2000,\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 0.8, step=0.05),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'random_state': RANDOM_SEED,\n","        'num_threads': 4,\n","        'verbose': 0\n","    }\n","\n","    # 5-fold 교차 검증 준비\n","    kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n","    \n","    mae_list = []\n","\n","    # 5-fold 교차 검증 수행\n","    for fold, (train_idx, val_idx) in enumerate(kf.split(X_all), 1):\n","        X_train, X_val = X_all.iloc[train_idx], X_all.iloc[val_idx]\n","        y_train, y_val = y_all.iloc[train_idx], y_all.iloc[val_idx]\n","        \n","        train_data = lgb.Dataset(X_train, label=y_train)\n","        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n","        \n","        model = lgb.train(\n","            params,\n","            train_data,\n","            valid_sets=[val_data],\n","            valid_names='validation',\n","            callbacks=[lgb.early_stopping(stopping_rounds=100)]\n","        )\n","        \n","        # 검증 세트에 대한 예측\n","        val_pred = model.predict(X_val)\n","        \n","        # MAE 계산\n","        mae = mean_absolute_error(y_val, val_pred)\n","        mae_list.append(mae)\n","\n","    # 평균 MAE 반환\n","    return np.mean(mae_list)\n","\n","# Optuna 연구 생성 및 최적화 실행\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=20, n_jobs=2)\n","\n","# 최적의 하이퍼파라미터 및 성능 출력\n","print(\"Best parameters:\", study.best_params)\n","print(\"Best MAE:\", study.best_value)"]},{"cell_type":"markdown","metadata":{},"source":["# Catboost 모델 훈련"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# # wandb 초기화\n","# wandb.init(project=\"house_price_prediction\", name=\"catboost_gpu\")  # 실험명에 따라 name 변경해주기!!\n","\n","# # 카테고리형 변수 정의\n","# cat_features = ['floor', 'built_year', 'elementary', 'middle', 'high', 'cluster']\n","\n","# # CatBoost 파라미터 설정\n","# cat_params = {\n","#     'iterations': 10000,\n","#     'loss_function': 'RMSE',\n","#     'eval_metric': 'MAE',\n","#     'early_stopping_rounds': 100,\n","#     'verbose': 100,\n","#     'random_seed': RANDOM_SEED,\n","#     'task_type': 'GPU',\n","#     'devices': '0'\n","# }\n","\n","# # wandb에 파라미터 로깅\n","# wandb.config.update(cat_params)\n","\n","# # CatBoost 데이터셋 생성\n","# train_pool = Pool(X_train, y_train)\n","# valid_pool = Pool(X_holdout, y_holdout)\n","\n","# # CatBoost 모델 생성\n","# cat_model = CatBoostRegressor(**cat_params)\n","\n","# # 모델 학습\n","# cat_model.fit(\n","#     train_pool,\n","#     eval_set=valid_pool,\n","#     use_best_model=True,\n","#     # callbacks=[WandbCallback()]\n","# )\n","\n","# # Holdout 데이터 예측\n","# cat_holdout_pred = cat_model.predict(X_holdout)\n","\n","# # 성능 메트릭 계산\n","# cat_holdout_mae = mean_absolute_error(y_holdout, cat_holdout_pred)\n","# cat_holdout_rmse = np.sqrt(mean_squared_error(y_holdout, cat_holdout_pred))\n","# cat_holdout_r2 = r2_score(y_holdout, cat_holdout_pred)\n","\n","# # wandb에 성능 지표 로깅\n","# wandb.log({\n","#     \"holdout_mae\": cat_holdout_mae,\n","#     \"holdout_rmse\": cat_holdout_rmse,\n","#     \"holdout_r2\": cat_holdout_r2\n","# })\n","\n","# # 결과 출력\n","# print(\"Holdout 데이터셋 CatBoost 성능:\")\n","# print(f\"MAE: {cat_holdout_mae:.2f}\")\n","# print(f\"RMSE: {cat_holdout_rmse:.2f}\")\n","# print(f\"R²: {cat_holdout_r2:.2f}\")\n","\n","# # 특성 중요도 로깅\n","# feature_importance = cat_model.get_feature_importance()\n","# feature_importance_dict = dict(zip(X_train.columns, feature_importance))\n","# wandb.log({\"feature_importance\": wandb.plot.bar(wandb.Table(data=[[k, v] for k, v in feature_importance_dict.items()], columns=[\"feature\", \"importance\"]), \"feature\", \"importance\", title=\"Feature Importance\")})\n","\n","# # wandb 실험 종료\n","# wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"ls0JM6nP8-GG"},"source":["# Sample Submission 제출하기"]},{"cell_type":"markdown","metadata":{},"source":["## 전체 데이터로 클러스터링 다시하기"]},{"cell_type":"markdown","metadata":{},"source":["### DBSCAN"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# # DBSCAN 클러스터 정보를 포함한 데이터셋 생성\n","# X_all['cluster'], X_test['cluster'] = ft.apply_dbscan_clustering(X_all, X_test)\n","# # 피처 선택\n","# X_all = X_all[train_columns]\n","# X_test = X_test[train_columns]"]},{"cell_type":"markdown","metadata":{},"source":["## 전체 데이터로 LGBM 재학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ej2VObrf8-GG"},"outputs":[],"source":["# LightGBM 파라미터 설정\n","lgb_params = {\n","    'objective': 'regression',\n","    'metric': 'mae',\n","    'boosting_type': 'gbdt',\n","    'num_leaves': 1200,  # 각 트리의 최대 리프 수\n","    'min_samples': 20,  # 각 리프의 최소 샘플 수\n","    'learning_rate': 0.035,\n","    'n_estimators': 2000,  # 트리를 몇 개 사용하여 부스팅할건지, epoch와 비슷함\n","    'feature_fraction': 0.65,  # 각 트리가 사용할 컬럼의 비율 eg. 0.8이면 10개의 컬럼 중 8개만 사용\n","    # 'bagging_fraction': 0.65,  # 각 트리가 사용할 데이터의 비율 eg. 0.8이면 80퍼센트의 데이터 샘플만 사용\n","    # 'bagging_freq': 0,  # 몇번째 트리마다 배깅을 적용할건지 eg. 5이면 5번째 트리마다 배깅 적용\n","    'lambda_l1': 1.1939606848809192,\n","    'lambda_l2': 4.389852271719141,\n","    'verbose': -1,\n","    'random_state': RANDOM_SEED\n","}\n","\n","\n","mdl.train_lgb(X_all, y_all, lgb_params, X_test=X_test, sample_submission=sample_submission)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 전체 데이터로 Catboost 재학습"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# # 피처 선택\n","# X_all = X_all[train_columns]\n","# X_test = X_test[train_columns]\n","\n","# # CatBoost 파라미터 설정\n","# cat_params = {\n","#     'iterations': 1000,\n","#     'loss_function': 'RMSE',\n","#     'eval_metric': 'MAE',\n","#     'verbose': 100,\n","#     'random_seed': RANDOM_SEED\n","# }\n","\n","# # CatBoost 데이터셋 생성\n","# all_pool = Pool(X_all, y_all)\n","# test_pool = Pool(X_test)\n","\n","# # CatBoost 모델 생성\n","# cat_model = CatBoostRegressor(**cat_params)\n","\n","# # 모델 학습\n","# cat_model.fit(all_pool)\n","\n","# # 추론\n","# cat_test_pred = cat_model.predict(test_pool)\n","# sample_submission['deposit'] = cat_test_pred\n","# sample_submission.to_csv('output.csv', index=False, encoding='utf-8-sig')"]}],"metadata":{"colab":{"collapsed_sections":["9uxQLCBR8-F8","mqCLjTRj8-GA","FdLe3hAC8-GB","CBFwVC218-GC","OdKZ3dlSdRZ3","IsEZSUGZq5Lb","yizD1AVMq7x8","I3deDvKfKD5p","bVeYhbb9B-P_","nPi_ZjCICAbm","I3aeCdqDgFLx","arhqTLnggEoP","EmPpm3r28-GC","o81426wF8-GD","G_AXG_jQ8-GE","8bwjTmxuBfkh","BC_OAK1A8-GF","w8fJH92a8-GF","ls0JM6nP8-GG"],"provenance":[]},"kernelspec":{"display_name":"aitech","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
